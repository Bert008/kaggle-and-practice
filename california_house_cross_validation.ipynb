{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0825b417-3bcc-4903-b32a-05f7b61ac96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# leemos los datos\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# removemos las filas con missing values, separamos de los predictores\n",
    "train_data.dropna(axis = 0, subset = ['SalePrice'], inplace = True)\n",
    "y = train_data.SalePrice\n",
    "train_data.drop(['SalePrice'], axis = 1, inplace = True)\n",
    "\n",
    "# seleccionamos las columnas numericas que utilizaresmos\n",
    "numeric_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float']]\n",
    "X = train_data[numeric_cols].copy()\n",
    "X_test = test_data[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fbf5b-ada1-44c0-bfc0-17137bf1bdc8",
   "metadata": {},
   "source": [
    "El proceso en nuesto codigo sera el siguiente. Utilizaresmos SimpleImputer para remplazar los datos de los valores faltantes, ese sera el preprocessor. Despues utilizaresmo el modelo con RandomForestRegressor para hacer las predicciones, el trabajo sera econtrar un forma de ver con cuantos arboles trabaja mejor el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9be013-d6f2-4c8f-97bc-6e1ee6bd6945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps = [\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators = 50, random_state = 0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a50ce71-2027-4638-a65d-6a9eaad57126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE scoring avg:  18311.538589041094\n"
     ]
    }
   ],
   "source": [
    "# ahora veamos que este pipeline sirve para ejecutar cun cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(my_pipeline, X, y, cv = 5, scoring = 'neg_mean_absolute_error') * -1\n",
    "\n",
    "print(\"MAE scoring avg: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4fe70-177e-4c6d-9746-94cfc29ec76f",
   "metadata": {},
   "source": [
    "# Escribamos una funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f76506-db67-4b40-93e9-58759cc66803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators):\n",
    "    my_pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
